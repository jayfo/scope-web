{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61593d0f-147b-4e8a-beaf-cd976cc6baee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Patient Data Export\n",
    "\n",
    "A notebook exporting patient data for study analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e6585-0e45-4a7c-9b1a-69def1590cb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a95cf5-b99d-4ea9-8103-c05da885e137",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a14340-9b0a-463e-a054-b5229a570e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import operator\n",
    "import pathlib\n",
    "import re\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import IPython.display\n",
    "import ipywidgets\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "import pyzipper\n",
    "from openpyxl.cell.cell import ILLEGAL_CHARACTERS_RE\n",
    "from scope.documents import document_set\n",
    "from scope.populate.data.archive import Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286d4c9-06f8-4068-9ef7-71951a155c1b",
   "metadata": {},
   "source": [
    "### Constants and Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e556573-c100-4716-8884-af2539d96de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In development, it can be helpful to sample a subset of patients.\n",
    "# If DEVELOPMENT_SAMPLE_PATIENTS <= 0, process all patients.\n",
    "# If DEVELOPMENT_SAMPLE_PATIENTS > 0, randomly sample DEVELOPMENT_SAMPLE_PATIENTS patients.\n",
    "DEVELOPMENT_SAMPLE_PATIENTS: int = 10\n",
    "\n",
    "DISPLAY_PREPARE_PATIENTS: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5e56d-fe30-4482-a286-e354f56089f5",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4d93e-bb42-447f-bff5-b8bd29d0ce67",
   "metadata": {},
   "source": [
    "### Utility: excel_dataframe\n",
    "\n",
    "Returns bytes containing an Excel export of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03082f9-c850-4345-b975-b54edd8408f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_dataframe(df: pd.DataFrame) -> bytes:\n",
    "    iobytes = io.BytesIO()\n",
    "    df.to_excel(iobytes, index=False)\n",
    "\n",
    "    return iobytes.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99409d53-ba6c-41af-9709-9bc14f428bdd",
   "metadata": {},
   "source": [
    "### Utility: markdown_documentation\n",
    "\n",
    "Returns a string containing markdown content recovered from a cell in this notebook.\n",
    "\n",
    "Intended to allow including the content of markdown cells as documentation in an export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed34a35-5424-43fc-91a7-75c1de3eace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_documentation(documentation_name: str) -> str:\n",
    "    # Load this same notebook.\n",
    "    notebook = nbformat.read(\"patientdata.ipynb\", nbformat.NO_CONVERT)\n",
    "\n",
    "    # Go through each cell, looking for a match.\n",
    "    for cell_current in notebook[\"cells\"]:\n",
    "        match = True\n",
    "        if match:\n",
    "            match = cell_current[\"cell_type\"] == \"markdown\"\n",
    "        if match:\n",
    "            match = re.match(\n",
    "                \"^(#*) Documentation: ({})\\\\n(.*)\".format(documentation_name),\n",
    "                cell_current[\"source\"],\n",
    "            )\n",
    "\n",
    "        if match:\n",
    "            return cell_current[\"source\"]\n",
    "\n",
    "    # If no match was found, raise a ValueError.\n",
    "    raise ValueError(\n",
    "        \"No matching documentation cell found: {}\".format(documentation_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e33a0-8776-4709-9bfe-e7f3e64e5556",
   "metadata": {},
   "source": [
    "### Utility: patient_data_export_file\n",
    "\n",
    "The path and contents of a file to be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545241d-24f5-46c1-83ba-d393f27e4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportFileType(Enum):\n",
    "    EXCEL = \"EXCEL\"\n",
    "    MARKDOWN = \"MARKDOWN\"\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ExportFile:\n",
    "    path: pathlib.Path\n",
    "    type: ExportFileType\n",
    "    bytes: Optional[bytes]\n",
    "    text: Optional[str]\n",
    "\n",
    "    @classmethod\n",
    "    def from_excel(\n",
    "        cls,\n",
    "        path: Union[pathlib.Path, str],\n",
    "        excel: bytes,\n",
    "    ):\n",
    "        return ExportFile(\n",
    "            path=pathlib.Path(path),\n",
    "            type=ExportFileType.EXCEL,\n",
    "            bytes=excel,\n",
    "            text=None,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_markdown(\n",
    "        cls,\n",
    "        path: Union[pathlib.Path, str],\n",
    "        markdown: str,\n",
    "    ):\n",
    "        return ExportFile(\n",
    "            path=pathlib.Path(path),\n",
    "            type=ExportFileType.MARKDOWN,\n",
    "            bytes=None,\n",
    "            text=markdown,\n",
    "        )\n",
    "\n",
    "\n",
    "def patient_data_export_file(file: ExportFile):\n",
    "    patient_data_export_file_list.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778098a-f807-48e4-b6ee-8323da24dfcd",
   "metadata": {},
   "source": [
    "### Utility: dataframe_sanitize\n",
    "\n",
    "Sanitize contents of a dataframe that otherwise cannot be written to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf9fae-1ce8-4251-9cb0-209faa666ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_sanitize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def sanitize_cell(value):\n",
    "        if type(value) == str:\n",
    "            value = ILLEGAL_CHARACTERS_RE.sub(\"?\", value)\n",
    "    \n",
    "        return value\n",
    "\n",
    "    return df.map(sanitize_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb2af0-4ce5-46e3-adc7-2b9c7d2fe10e",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6a8f0-57ed-4d91-a97e-f21652c495d6",
   "metadata": {},
   "source": [
    "### Input Archive Suffix: archive_suffix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42980a3-e834-44d8-8737-cdfdfa562b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain suffix indicating desired version of encrypted archives.\n",
    "# Do not include the '.zip' suffix.\n",
    "archive_suffix = input(\"Encrypted archive suffix: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c182cd-b385-4251-8c92-32bd4f985b44",
   "metadata": {},
   "source": [
    "### Input Archive Password: archive_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7154a-6053-44d7-b6f4-504cfc4d0d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain password to encrypted archives.\n",
    "archive_password = input(\"Encrypted archive password: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc219c-78b4-4d41-b69e-97b28867faa5",
   "metadata": {},
   "source": [
    "### Utility: archive_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9820e0-810c-451b-aabb-8d8782de1b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain password to encrypted archives.\n",
    "archive_dir_path = \"../../../secrets/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff265d-ed78-49b9-981f-96aff3c79488",
   "metadata": {},
   "source": [
    "## Load Archives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51623c25-8317-489a-ae4d-579e97684a21",
   "metadata": {},
   "source": [
    "### Decrypt Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc41dd1-4a40-4256-8ba8-8c34486c1021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decrypt_archives():\n",
    "    # Obtain name for each archive.\n",
    "    archive_multicare_file_name = \"archive_multicare_{}.zip\".format(archive_suffix)\n",
    "    archive_scca_file_name = \"archive_scca_{}.zip\".format(archive_suffix)\n",
    "\n",
    "    # Obtain a full path to encrypted archive, relative to the location of the notebook.\n",
    "    # Expects the encrypted archive to be in the \"secrets/data\" directory.\n",
    "    archive_multicare_path = pathlib.Path(\n",
    "        archive_dir_path,\n",
    "        archive_multicare_file_name,\n",
    "    )\n",
    "    archive_scca_path = pathlib.Path(\n",
    "        archive_dir_path,\n",
    "        archive_scca_file_name,\n",
    "    )\n",
    "\n",
    "    print(\"Decrypting archive:\")\n",
    "    print(\"{}\".format(archive_multicare_path.resolve()))\n",
    "\n",
    "    # Obtain the archive.\n",
    "    archive_multicare = Archive.read_archive(\n",
    "        archive_path=archive_multicare_path,\n",
    "        password=archive_password,\n",
    "    )\n",
    "\n",
    "    print(\"{} documents.\".format(len(archive_multicare.entries.values())))\n",
    "    print(\"\")\n",
    "    print(\"Decrypting archive:\")\n",
    "    print(\"{}\".format(archive_scca_path.resolve()))\n",
    "\n",
    "    # Obtain the archive.\n",
    "    archive_scca = Archive.read_archive(\n",
    "        archive_path=archive_scca_path,\n",
    "        password=archive_password,\n",
    "    )\n",
    "\n",
    "    print(\"{} documents.\".format(len(archive_scca.entries.values())))\n",
    "\n",
    "    return archive_multicare, archive_scca\n",
    "\n",
    "\n",
    "archive_multicare, archive_scca = decrypt_archives()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f73156-10d5-4019-970c-f02ea8b8dd5b",
   "metadata": {},
   "source": [
    "### Process Archives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f38ca9-122f-4d40-8270-69c3964418ea",
   "metadata": {},
   "source": [
    "#### Combine Patients DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e6366-e7b0-4f3c-812b-033905a4cc2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_patients_dataframes():\n",
    "    # Get patient documents from MultiCare.\n",
    "    documents_multicare_patients = (\n",
    "        archive_multicare.collection_documents(\n",
    "            collection=\"patients\",\n",
    "        )\n",
    "        .remove_sentinel()\n",
    "        .remove_revisions()\n",
    "    )\n",
    "    df_multicare_patients = pd.DataFrame.from_records(\n",
    "        documents_multicare_patients.documents\n",
    "    )\n",
    "    df_multicare_patients[\"database\"] = \"multicare\"\n",
    "\n",
    "    # Get patient documents from SCCA.\n",
    "    documents_scca_patients = (\n",
    "        archive_scca.collection_documents(\n",
    "            collection=\"patients\",\n",
    "        )\n",
    "        .remove_sentinel()\n",
    "        .remove_revisions()\n",
    "    )\n",
    "    df_scca_patients = pd.DataFrame.from_records(documents_scca_patients.documents)\n",
    "    df_scca_patients[\"database\"] = \"fhcc\"\n",
    "\n",
    "    # Unify all current patient documents.\n",
    "    df_combined_patients = pd.concat(\n",
    "        [df_multicare_patients, df_scca_patients]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Sanitize once so contents dataframe can be exported.\n",
    "    df_combined_patients = dataframe_sanitize(df_combined_patients)\n",
    "\n",
    "    return df_combined_patients\n",
    "\n",
    "\n",
    "df_archive_patients_raw = combine_patients_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7038f7-35aa-4cdd-9024-e0247c118838",
   "metadata": {},
   "source": [
    "#### Reset Filtering and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf30078-c24d-462b-bdcf-8295205810c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_archive_patients = df_archive_patients_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7526ef-f9fb-4419-90c7-4c67e26e3e2d",
   "metadata": {},
   "source": [
    "#### Filter Pilot Patients\n",
    "\n",
    "Remove the 6 pilot patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f432d-8e6b-4039-97da-fc2d9bef3dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_archive_patients = df_archive_patients.drop(\n",
    "    df_archive_patients[\n",
    "        df_archive_patients[\"patientId\"].isin(\n",
    "            [\n",
    "                \"ymzwx6e6w6kqi\",\n",
    "                \"mmmb54v52l7re\",\n",
    "                \"ouoa4ucldbhie\",\n",
    "                \"zazst4yu23a5q\",\n",
    "                \"wf4btxqjtd2oa\",\n",
    "                \"s3bcmgmp7gdss\",\n",
    "            ]\n",
    "        )\n",
    "    ].index\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb113eeb-81af-4e9f-883c-82b4e2d9264f",
   "metadata": {},
   "source": [
    "#### Sample Patients\n",
    "\n",
    "In development, it can be helpful to sample a subset of patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8ff65-aab7-45ab-9a0d-03ec38e54e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVELOPMENT_SAMPLE_PATIENTS > 0:\n",
    "    df_archive_patients = df_archive_patients.sample(\n",
    "        n=DEVELOPMENT_SAMPLE_PATIENTS\n",
    "    ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfcc533-1006-466d-aeee-d205cfbb2308",
   "metadata": {},
   "source": [
    "#### Utility: patient_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1dec2-f5aa-4869-8fa0-0656e9233426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a helper for accessing the document collection of a unified patient.\n",
    "def patient_documents(row_patient) -> document_set.DocumentSet:\n",
    "    if row_patient[\"database\"] == \"multicare\":\n",
    "        archive = archive_multicare\n",
    "    elif row_patient[\"database\"] == \"fhcc\":\n",
    "        archive = archive_scca\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    return archive.collection_documents(collection=row_patient[\"collection\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b46616-323b-44e0-a8bd-823bc56d08cb",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0294d90-f988-4641-89b7-bf71b035a3a0",
   "metadata": {},
   "source": [
    "### Prepare Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43060c1-9fde-4d5b-a58e-34d8d32dffe0",
   "metadata": {},
   "source": [
    "#### Documentation: Patients\n",
    "\n",
    "- An export of all patientIdentity documents.\n",
    "  These are stored separately from the documents associated with each patient.\n",
    "  They provide an index of all patients, then we can access documents for an individual patient.\n",
    "\n",
    "- A patientIdentity may have been modified throughout the study (e.g., to change a patient name or email address).\n",
    "  If it was modified, this export includes only the final version of that document.\n",
    "  There is therefore exactly one row per patient.\n",
    "\n",
    "- Several fields are removed to reduce clutter:\n",
    "  - `_id`\n",
    "  - `_rev`\n",
    "  - `_set_id`\n",
    "  - `cognitoAccount`\n",
    "- Several identifiers are removed:\n",
    "  - `email`, as part of `cognitoAccount`\n",
    "  - `name`\n",
    "\n",
    "- Although it appears to be clutter, `collection` is used by later processing and should not be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e3eb78-48da-4593-aa19-39c0c4c39956",
   "metadata": {},
   "source": [
    "#### Data: df_patients_raw\n",
    "\n",
    "A dataframe containing the identity of each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88901c3d-30ef-4f1f-95ea-0635018f4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients_raw = df_archive_patients.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e604e-3f76-4d03-bf94-40f8b1e67286",
   "metadata": {},
   "source": [
    "#### Data: df_patients\n",
    "\n",
    "A dataframe containing the identity of each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6efb1-2552-4b66-b550-f4bc922f08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = df_patients_raw.copy()\n",
    "\n",
    "if DISPLAY_PREPARE_PATIENTS:\n",
    "    IPython.display.display(df_patients_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68378409-9efc-41d5-9027-3304673d915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = df_patients.drop(\n",
    "    [\n",
    "        # Remove clutter.\n",
    "        \"_id\",\n",
    "        \"_rev\",\n",
    "        \"_set_id\",\n",
    "        # Remove identifiers.\n",
    "        \"cognitoAccount\",  # Includes email.\n",
    "        \"name\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Order columns for readability.\n",
    "df_patients = df_patients[\n",
    "    [\n",
    "        \"_type\",\n",
    "        \"database\",\n",
    "        \"patientId\",\n",
    "        \"collection\",\n",
    "        \"MRN\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Sort rows for readability.\n",
    "df_patients = df_patients.sort_values(\n",
    "    [\n",
    "        \"_type\",\n",
    "        \"database\",\n",
    "        \"patientId\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "if DISPLAY_PREPARE_PATIENTS:\n",
    "    IPython.display.display(df_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77f0b0-a958-4d59-b51e-f0595e9f4b58",
   "metadata": {},
   "source": [
    "### Prepare Per-Patient DocumentSets and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606174cc-fbc4-4a54-b410-ddca1387cf82",
   "metadata": {},
   "source": [
    "#### Data: patient_id_to_documentset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee2a76-b95b-4c69-9734-94abaf7badf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_patient_id_to_documentset():\n",
    "    patient_id_to_documentset = {}\n",
    "\n",
    "    progress_max = len(df_patients)\n",
    "    progress_patient_count = ipywidgets.IntProgress(min=0, max=progress_max)\n",
    "\n",
    "    print(\"Preparing DocumentSet for {} Patients\".format(progress_max))\n",
    "    IPython.display.display(progress_patient_count)\n",
    "\n",
    "    progress_patient_count.description = \"{}/{}\".format(0, progress_max)\n",
    "    for patient_count, (row_current, patient_current) in enumerate(\n",
    "        df_patients.iterrows()\n",
    "    ):\n",
    "        patient_id_current = patient_current[\"patientId\"]\n",
    "        patient_collection = patient_documents(patient_current.to_dict())\n",
    "\n",
    "        patient_id_to_documentset[patient_id_current] = patient_collection\n",
    "\n",
    "        progress_patient_count.description = \"{}/{}\".format(\n",
    "            patient_count + 1, progress_max\n",
    "        )\n",
    "        progress_patient_count.value = patient_count + 1\n",
    "\n",
    "    return patient_id_to_documentset\n",
    "\n",
    "\n",
    "patient_id_to_documentset = prepare_patient_id_to_documentset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86fcbb-f16c-4a82-b4bb-250aafb8692a",
   "metadata": {},
   "source": [
    "#### Transform: transform_add_patient_id\n",
    "\n",
    "Add a `patientId` column to each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8941d-7f54-44d8-bb78-3b6b7f558d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_add_patient_id(\n",
    "    df_documents: pd.DataFrame,\n",
    "    *,\n",
    "    patient_id,\n",
    ") -> pd.DataFrame:\n",
    "    df_documents = df_documents.copy()\n",
    "    df_documents[\"patientId\"] = patient_id\n",
    "\n",
    "    df_documents = dataframe_format_export(\n",
    "        df_documents,\n",
    "        drop_empty_columns=False,\n",
    "        drop_columns=[],\n",
    "        sort_columns=[\"patientId\"],\n",
    "        sort_rows_by_columns=[],\n",
    "    )\n",
    "\n",
    "    return df_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4ee33-c599-4ad1-b283-50822f08f533",
   "metadata": {},
   "source": [
    "#### Data: patient_id_to_df_documents_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b988c74-ea09-456b-811b-ff2287b0d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_patient_id_to_df_documents_raw():\n",
    "    patient_id_to_df_documents_raw = {}\n",
    "\n",
    "    progress_max = len(patient_id_to_documentset)\n",
    "    progress_patient_count = ipywidgets.IntProgress(min=0, max=progress_max)\n",
    "\n",
    "    print(\"Preparing DataFrame for {} Patients\".format(progress_max))\n",
    "    IPython.display.display(progress_patient_count)\n",
    "\n",
    "    progress_patient_count.description = \"{}/{}\".format(0, progress_max)\n",
    "    for patient_count, (patient_id_current, patient_documentset_current) in enumerate(\n",
    "        patient_id_to_documentset.items()\n",
    "    ):\n",
    "        df_documents_raw_current = pd.DataFrame.from_records(\n",
    "            patient_documentset_current.documents\n",
    "        )\n",
    "        df_documents_raw_current = dataframe_sanitize(df_documents_raw_current)\n",
    "\n",
    "        # Apply a minimal transform to the \"raw\" documents.\n",
    "        df_documents_raw_current = transform_add_patient_id(\n",
    "            df_documents_raw_current,\n",
    "            patient_id=patient_id_current\n",
    "        )\n",
    "\n",
    "        patient_id_to_df_documents_raw[patient_id_current] = df_documents_raw_current\n",
    "\n",
    "        progress_patient_count.description = \"{}/{}\".format(\n",
    "            patient_count + 1, progress_max\n",
    "        )\n",
    "        progress_patient_count.value = patient_count + 1\n",
    "\n",
    "    return patient_id_to_df_documents_raw\n",
    "\n",
    "\n",
    "patient_id_to_df_documents_raw = prepare_patient_id_to_df_documents_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d598e15-3a4c-4d18-bd1b-2a0c6c78c385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_documents_raw = pd.concat(patient_id_to_df_documents_raw.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9244cc-a28e-4fb7-aa1c-c4b771ae85f5",
   "metadata": {},
   "source": [
    "## Transform Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c52d7-ac3c-4a7f-b3b0-cc94e4b071b2",
   "metadata": {},
   "source": [
    "### Transform: transform_assessment_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb9495-7e17-446e-a4d1-312b5fc79193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_assessment_log(\n",
    "    df_documents: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    # Pull each value of the gad-7 assessment scale out to its own column.\n",
    "    def _transform_gad7_points(\n",
    "        df_documents: pd.DataFrame,\n",
    "    ) -> pd.DataFrame:\n",
    "        def _factory_transform_gad7_points_key(keyJson):\n",
    "            def _transform_gad7_points_key(row):\n",
    "                if row[\"_type\"] != \"assessmentLog\":\n",
    "                    return None\n",
    "                if row[\"assessmentId\"] != \"gad-7\":\n",
    "                    return None\n",
    "                if not row[\"pointValues\"]:\n",
    "                    return None\n",
    "\n",
    "                return row[\"pointValues\"][keyJson]\n",
    "\n",
    "            return _transform_gad7_points_key\n",
    "\n",
    "        gad7EnumMap = {\n",
    "            \"Anxious\": \"gad7Anxious\",\n",
    "            \"Constant worrying\": \"gad7ConstantWorrying\",\n",
    "            \"Worrying too much\": \"gad7WorryingTooMuch\",\n",
    "            \"Trouble relaxing\": \"gad7TroubleRelaxing\",\n",
    "            \"Restless\": \"gad7Restless\",\n",
    "            \"Irritable\": \"gad7Irritable\",\n",
    "            \"Afraid\": \"gad7Afraid\",\n",
    "        }\n",
    "\n",
    "        for (keyJson, keyExport) in gad7EnumMap.items():\n",
    "            df_documents[keyExport] = df_documents.apply(\n",
    "                _factory_transform_gad7_points_key(keyJson), axis=1\n",
    "            )\n",
    "\n",
    "        return df_documents\n",
    "\n",
    "    # Obtain or calculate a gad-7 score.\n",
    "    def _transform_gad7_score(row):\n",
    "        if row[\"_type\"] != \"assessmentLog\":\n",
    "            return None\n",
    "        if row[\"assessmentId\"] != \"gad-7\":\n",
    "            return None\n",
    "\n",
    "        # Some rows already provide a totalScore.\n",
    "        if \"totalScore\" in row and not pd.isna(row[\"totalScore\"]):\n",
    "            return row[\"totalScore\"]\n",
    "\n",
    "        # Otherwise we need to sum the pointValues.\n",
    "        if \"pointValues\" in row and row[\"pointValues\"]:\n",
    "            return sum(row[\"pointValues\"].values())\n",
    "\n",
    "        # We should always have one or the other.\n",
    "        raise ValueError()\n",
    "\n",
    "    # Pull each value of the phq-9 assessment scale out to its own column.\n",
    "    def _transform_phq9_points(\n",
    "        df_documents: pd.DataFrame,\n",
    "    ) -> pd.DataFrame:\n",
    "        def _factory_transform_phq9_points_key(keyJson):\n",
    "            def _transform_phq9_points_key(row):\n",
    "                if row[\"_type\"] != \"assessmentLog\":\n",
    "                    return None\n",
    "                if row[\"assessmentId\"] != \"phq-9\":\n",
    "                    return None\n",
    "                if not row[\"pointValues\"]:\n",
    "                    return None\n",
    "\n",
    "                return row[\"pointValues\"][keyJson]\n",
    "\n",
    "            return _transform_phq9_points_key\n",
    "\n",
    "        phq9EnumMap = {\n",
    "            \"Interest\": \"phq9Interest\",\n",
    "            \"Mood\": \"phq9Mood\",\n",
    "            \"Sleep\": \"phq9Sleep\",\n",
    "            \"Energy\": \"phq9Energy\",\n",
    "            \"Appetite\": \"phq9Appetite\",\n",
    "            \"Guilt\": \"phq9Guilt\",\n",
    "            \"Concentrating\": \"phq9Concentrating\",\n",
    "            \"Motor\": \"phq9Motor\",\n",
    "            \"Suicide\": \"phq9Suicide\",\n",
    "        }\n",
    "\n",
    "        for (keyJson, keyExport) in phq9EnumMap.items():\n",
    "            df_documents[keyExport] = df_documents.apply(\n",
    "                _factory_transform_phq9_points_key(keyJson), axis=1\n",
    "            )\n",
    "\n",
    "        return df_documents\n",
    "\n",
    "    # Obtain or calculate a phq-9 score.\n",
    "    def _transform_phq9_score(row):\n",
    "        if row[\"_type\"] != \"assessmentLog\":\n",
    "            return None\n",
    "        if row[\"assessmentId\"] != \"phq-9\":\n",
    "            return None\n",
    "\n",
    "        # Some rows already provide a totalScore.\n",
    "        if \"totalScore\" in row and not pd.isna(row[\"totalScore\"]):\n",
    "            return row[\"totalScore\"]\n",
    "\n",
    "        # Otherwise we need to sum the pointValues.\n",
    "        if \"pointValues\" in row and row[\"pointValues\"]:\n",
    "            return sum(row[\"pointValues\"].values())\n",
    "\n",
    "        # We should always have one or the other.\n",
    "        raise ValueError()\n",
    "\n",
    "    df_documents = df_documents.copy()\n",
    "    df_documents = _transform_gad7_points(df_documents)\n",
    "    df_documents[\"gad7Score\"] = df_documents.apply(_transform_gad7_score, axis=1)\n",
    "    df_documents = _transform_phq9_points(df_documents)\n",
    "    df_documents[\"phq9Score\"] = df_documents.apply(_transform_phq9_score, axis=1)\n",
    "\n",
    "    return df_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f3bf5-d492-4353-a4ff-1f77bb1cbe8f",
   "metadata": {},
   "source": [
    "### Utility: apply_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5558e07-0fab-4650-acf5-c7007b762e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transforms(\n",
    "    df_documents: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    df_documents = transform_assessment_log(\n",
    "        df_documents,\n",
    "    )\n",
    "    \n",
    "    return df_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59dbb08-7ded-42e8-ae73-f7311bd1d217",
   "metadata": {},
   "source": [
    "### Data: patient_id_to_df_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9d127-5d8e-43df-a55b-b2907893927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_transform_patient_documents():\n",
    "    patient_id_to_df_documents = {}\n",
    "\n",
    "    progress_max = len(patient_id_to_df_documents_raw)\n",
    "    progress_patient_count = ipywidgets.IntProgress(min=0, max=progress_max)\n",
    "\n",
    "    print(\"Transforming DataFrame for {} Patients\".format(progress_max))\n",
    "    IPython.display.display(progress_patient_count)\n",
    "\n",
    "    progress_patient_count.description = \"{}/{}\".format(0, progress_max)\n",
    "    for patient_count, (patient_id_current, df_documents_raw_current) in enumerate(\n",
    "        patient_id_to_df_documents_raw.items()\n",
    "    ):\n",
    "        patient_id_to_df_documents[patient_id_current] = apply_transforms(\n",
    "            df_documents_raw_current.copy(),\n",
    "        )\n",
    "\n",
    "        progress_patient_count.description = \"{}/{}\".format(\n",
    "            patient_count + 1, progress_max\n",
    "        )\n",
    "        progress_patient_count.value = patient_count + 1\n",
    "\n",
    "    return patient_id_to_df_documents\n",
    "\n",
    "\n",
    "patient_id_to_df_documents = prepare_transform_patient_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8cb36-0220-47b4-b57b-a7a791b3b465",
   "metadata": {},
   "source": [
    "### Prepare Combined Documents DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dcb54-9bac-44a1-a176-02ee7c7b8756",
   "metadata": {},
   "source": [
    "#### Data: df_documents_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a807d-8b1c-42ab-91cb-e0cea3b248e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents_raw = pd.concat(patient_id_to_df_documents_raw.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd59ea71-9392-42df-997c-8a3fe970ddae",
   "metadata": {},
   "source": [
    "#### Data: df_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1dce5a-e255-461e-9e22-f30700421863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents = pd.concat(patient_id_to_df_documents.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb3d9a0-e82a-4ec6-a3f4-c794317d0251",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fccca4-ed88-4191-b4e4-7315733f3bc9",
   "metadata": {},
   "source": [
    "### Utility: dataframe_format_export\n",
    "\n",
    "Formats a dataframe for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd1555-c7b8-4e2c-acf8-ad7c06eeddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_format_export(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    drop_empty_columns: bool,\n",
    "    drop_columns: List[str],\n",
    "    sort_columns: List[str],\n",
    "    sort_rows_by_columns: List[str],\n",
    ") -> pd.DataFrame:\n",
    "    # If requested, drop empty columns.\n",
    "    if drop_empty_columns:\n",
    "        empty_columns = []\n",
    "        for column_current in df.columns:\n",
    "            if (\n",
    "                df[column_current].isnull().all()\n",
    "                or (\n",
    "                    df[column_current].astype(str).str.strip().isin([\"\", \"nan\", \"None\"])\n",
    "                ).all()\n",
    "            ):\n",
    "                empty_columns.append(column_current)\n",
    "\n",
    "        df = df.drop(columns=empty_columns)\n",
    "\n",
    "    # If requested, drop specific columns.\n",
    "    # Be robust to the possibility that a column is not present.\n",
    "    if drop_columns:\n",
    "        df = df.drop(columns=drop_columns, errors=\"ignore\")\n",
    "\n",
    "    # If requested, sort specific columns to the front.\n",
    "    # Be robust to the possibility that a column is not present.\n",
    "    # Be robust to the presence of additional columns.\n",
    "    # Preserve existing order of additional columns after requested columns.\n",
    "    if sort_columns:\n",
    "        sort_columns = [\n",
    "            column_current\n",
    "            for column_current in sort_columns\n",
    "            if column_current in df.columns\n",
    "        ]\n",
    "        sort_columns = sort_columns + [\n",
    "            column_current\n",
    "            for column_current in df.columns\n",
    "            if column_current not in sort_columns\n",
    "        ]\n",
    "\n",
    "        df = df[sort_columns]\n",
    "\n",
    "    # If requested, sort rows by specific columns.\n",
    "    # Be robust to the possibility that a column is not present.\n",
    "    if sort_rows_by_columns:\n",
    "        sort_rows_by_columns = [\n",
    "            column_current\n",
    "            for column_current in sort_rows_by_columns\n",
    "            if column_current in df.columns\n",
    "        ]\n",
    "\n",
    "        df = df.sort_values(sort_rows_by_columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a9dcfc-4682-4f23-ad20-ccdd91e38fb9",
   "metadata": {},
   "source": [
    "### Reset Export File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba90b7e-cb19-495b-8c80-57b12fc8c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_export_file_list: List[ExportFile] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279b467-9bf2-4c93-b53a-6b03fe7a258c",
   "metadata": {},
   "source": [
    "### Documentation: Export\n",
    "\n",
    "- Data is originally taken from two database exports: one from FHCC and one from MultiCare.\n",
    "  - These raw data are merged, then a `database` column is added to indicate the origin of each patient.\n",
    "  - There were 6 pilot patients. These have been completely removed.\n",
    "\n",
    "- `patients.xlsx` is a list of all patients included in an export.\n",
    "  - Documentation is in `patients.md`.\n",
    "  - If included, `patients.raw.xlsx` is an unprocessed version of the same document.\n",
    "\n",
    "- `patients` is a folder, contains a folder for each patient.\n",
    "  - Patient folders are named `patient_{patientId}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42cd64-be60-45e8-a69c-36b981be8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_export_file(\n",
    "    ExportFile.from_markdown(\n",
    "        \"documentation.md\",\n",
    "        markdown_documentation(\"Export\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c852677-e238-4229-b02e-3ec8af7c3534",
   "metadata": {},
   "source": [
    "### Patients\n",
    "\n",
    "- Documented above in \"Documentation: Patients Export\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d5e1e-f15d-4533-ba1c-78eb70d9f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_export_file(\n",
    "    ExportFile.from_markdown(\n",
    "        \"patients.md\",\n",
    "        markdown_documentation(\"Patients\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "patient_data_export_file(\n",
    "    ExportFile.from_excel(\n",
    "        \"patients.xlsx\",\n",
    "        excel_dataframe(df_patients),\n",
    "    )\n",
    ")\n",
    "\n",
    "patient_data_export_file(\n",
    "    ExportFile.from_excel(\n",
    "        pathlib.Path(\n",
    "            \"data\",\n",
    "            \"patients.raw.xlsx\",\n",
    "        ),\n",
    "        excel_dataframe(df_patients_raw),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83807b0b-761c-451d-9890-44bbca8f7941",
   "metadata": {},
   "source": [
    "### Per-Patient Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25a6fe-3b81-48b0-ac6f-5d69f6b174e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_per_patient_documents():\n",
    "    progress_max = len(df_patients)\n",
    "    progress_patient_count = ipywidgets.IntProgress(min=0, max=progress_max)\n",
    "\n",
    "    print(\"Per-Patient Export for {} Patients\".format(progress_max))\n",
    "    IPython.display.display(progress_patient_count)\n",
    "\n",
    "    progress_patient_count.description = \"{}/{}\".format(0, progress_max)\n",
    "    for patient_count, (row_current, patient_current) in enumerate(\n",
    "        df_patients.iterrows()\n",
    "    ):\n",
    "        patient_id_current = patient_current[\"patientId\"]\n",
    "\n",
    "        df_documents_raw_current = patient_id_to_df_documents_raw[patient_id_current]\n",
    "        patient_data_export_file(\n",
    "            ExportFile.from_excel(\n",
    "                pathlib.Path(\n",
    "                    \"data\",\n",
    "                    \"patients\",\n",
    "                    \"patient_{}\".format(patient_id_current),\n",
    "                    \"patient_{}.raw.xlsx\".format(patient_id_current),\n",
    "                ),\n",
    "                excel_dataframe(df_documents_raw_current),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_documents_current = patient_id_to_df_documents[patient_id_current]\n",
    "        patient_data_export_file(\n",
    "            ExportFile.from_excel(\n",
    "                pathlib.Path(\n",
    "                    \"data\",\n",
    "                    \"patients\",\n",
    "                    \"patient_{}\".format(patient_id_current),\n",
    "                    \"patient_{}.transformed.xlsx\".format(patient_id_current),\n",
    "                ),\n",
    "                excel_dataframe(df_documents_current),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        progress_patient_count.description = \"{}/{}\".format(\n",
    "            patient_count + 1, progress_max\n",
    "        )\n",
    "        progress_patient_count.value = patient_count + 1\n",
    "\n",
    "\n",
    "export_per_patient_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892c73c-72a6-43b5-be63-97aa530cb952",
   "metadata": {},
   "source": [
    "### Combined Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce22c52-2af0-4003-b253-d0076c829797",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_export_file(\n",
    "    ExportFile.from_excel(\n",
    "        pathlib.Path(\n",
    "            \"data\",\n",
    "            \"documents.raw.xlsx\",\n",
    "        ),\n",
    "        excel_dataframe(df_documents_raw),\n",
    "    )\n",
    ")\n",
    "\n",
    "patient_data_export_file(\n",
    "    ExportFile.from_excel(\n",
    "        pathlib.Path(\n",
    "            \"data\",\n",
    "            \"documents.transformed.xlsx\",\n",
    "        ),\n",
    "        excel_dataframe(df_documents),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b86e1-e598-457a-ae69-43a6ab30c1c8",
   "metadata": {},
   "source": [
    "### Analysis: Assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd6967-edec-4d4a-b1f2-747d5b33d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_analysis_assessments():\n",
    "    df_assessments = dataframe_format_export(\n",
    "        df_documents[df_documents[\"_type\"] == \"assessmentLog\"],\n",
    "        drop_empty_columns=True,\n",
    "        drop_columns=[\"_id\", \"_type\", \"_set_id\"],\n",
    "        sort_columns=[\"patientId\", \"assessmentId\", \"assessmentLogId\", \"_rev\"],\n",
    "        sort_rows_by_columns=[\"patientId\", \"assessmentId\", \"assessmentLogId\", \"_rev\"],\n",
    "    )\n",
    "\n",
    "    patient_data_export_file(\n",
    "        ExportFile.from_excel(\n",
    "            \"assessments.xlsx\",\n",
    "            excel_dataframe(df_assessments),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "export_analysis_assessments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d4111-7faf-42ec-ba24-d65b9285810a",
   "metadata": {},
   "source": [
    "### Write Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e25a5-a095-42a2-bfc8-7f3de4ddb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The export is stored in a single zip file.\n",
    "with open(\n",
    "    pathlib.Path(\n",
    "        archive_dir_path,\n",
    "        \"export_{}.zip\".format(archive_suffix),\n",
    "    ),\n",
    "    mode=\"xb\",\n",
    ") as archive_file:\n",
    "    with pyzipper.AESZipFile(\n",
    "        archive_file,\n",
    "        \"w\",\n",
    "        compression=pyzipper.ZIP_LZMA,\n",
    "        encryption=pyzipper.WZ_AES,\n",
    "    ) as archive_zipfile:\n",
    "        # Set the password\n",
    "        archive_zipfile.setpassword(archive_password.encode(\"utf-8\"))\n",
    "\n",
    "        for file_current in patient_data_export_file_list:\n",
    "            if file_current.type == ExportFileType.EXCEL:\n",
    "                archive_zipfile.writestr(str(file_current.path), file_current.bytes)\n",
    "            elif file_current.type == ExportFileType.MARKDOWN:\n",
    "                archive_zipfile.writestr(\n",
    "                    str(file_current.path), file_current.text.encode(\"utf-8\")\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\"Unknown ExportFileType\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
